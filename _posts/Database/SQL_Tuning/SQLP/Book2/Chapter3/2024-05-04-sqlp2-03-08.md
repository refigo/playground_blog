---
title: <오라클 성능 고도화 원리와 해법2> Ch03-08 통계정보 2
date: 2024-05-04
categories: [Database, SQL Tuning]
tags: [SQLP]
---

## 오라클 성능 고도화 원리와 해법2 - Ch03-08 통계정보 2

### (1) 전략적인 통계수집 정책의 중요성

지금까지 설명한 카디널리티와 비용 계산식의 세부 사항을 항상 기억할 필요는 없다. 다만, 그 원리를 이해함으로써 통계정보 수집이 얼마나 중요한지 깨닫는 것이 매우 중요하다.

4절 '통계정보 1'에서 개발자를 대상으로 통계정보의 기본 개념을 설명한 것이라면, 이 절은 실제 통계정보를 수집하고 관리해야 할 DB 관리자들이 효과적인 통계정보 수집 전략을 세울 수 있도록 돕는 데 목적이 있다.

#### CBO 능력을 최대한 끌어 올리는 핵심 요소

이 책은 오라클 성능 문제를 주로 개발자 중심으로 설명하고 있다. 아키텍처를 다룰 때 개발자에게 필요한 내용 위주로 구성했음을 읽은 독자라면 이해할 것이다. 그럼에도 본 절에서 통계정보를 관리적인 수준까지 좀 더 깊이 다루려는 것은 통계정보가 CBO에게 미치는 영향력이 그만큼 절대적이기 때문이다.

'비용기반의 오라클 원리'를 번역하면서 역자 서문에 "옵티마이저가 그 능력을 최대한 발휘할 수 있도록 환경을 조성해주어야 한다”고 밝혔는데, 90%는 통계정보를 염두에 두고 한 말이다. 부정확한 통계정보를 옵티마이저에게 제공하고는 똑똑하지 못한 옵티마이저를 탓하는 일이 얼마나 많은가? "좋은 인덱스가 있는데도 엉뚱한 인덱스를 탄다", "해시 조인이 낫는데 NIL 조인을 한다" 등등.

그런데 많은 경우 그 원인이 통계정보 이상(꽃)에 있음을 이해할 수 있겠는가? 마지막 장에서 효율화 원리에 서 통계정보의 중요성을 강조하면서 아래와 같이 언급한 것을 상기하기 바란다.

```
"전쟁에서 효과적으로 싸우려면 정보력이 뒷받침되어야 한다. 정보가 불충분하면 적군의 수효가 10만 명에 이르는 데 불과 20 ~ 30 명 소대원을 이끌고 무모하게 돌격 명령을 내리는 소대장이 나올 수 있다."
```

#### DB 관리자의 핵심 역할은 통계정보 관리

독자가 DBA 역할을 맡고 있다면 본 절에서 설명하는 내용에 대해 지금까지 충분한 이해가 있었는지 되돌아봐야 한다. 현재 개발 중인 DB에 접속해 가장 마지막 통계정보 수집일자가 언제인지 확인해보기 바란다. 만약 중요한 거래 테이블들의 마지막 통계 수집일자가 대부분 오래된 상태라면, 성능 문제 때문에 수많은 밤을 지샌 원인이 통계정보에 있을 가능성이 있으므로 DBA에게 본 절의 내용을 소개해주기 바란다.

DBA라고 하면 흔히 오브젝트 생성 관리, 백업 & 복구, 트러블 슈팅 등을 떠올리지만 CIBO 환경에서 그 이상으로 중요한 역할은 통계정보 수집 정책을 세우고 그에 따라 통계정보를 안정적으로 운영 • 관리 하는 데에 있다. 문제 없던 쿼리가 어느 날 갑자기 악성 SQL로 돌변했다면 가장 먼저 확인해야 할 테이블 통계정보에 이상이 없는지 확인해보라. 십중팔구 통계정보에서 비롯된 문제일 것이다.

#### 통계정보 수집 시 고려사항

통계정보를 수집할 때 고려해야 할 중요한 네 가지 요소는 다음과 같다.

• 시간: 부하가 없는 시간대에 가능한 빠르게 수집을 완료해야 함
• 샘플 크기: 가능한 적은 양의 데이터를 읽어야 함
• 정확성: 전수검사할 때의 통계치에 근접해야 함
• 안정성: 데이터에 큰 변화가 없는데 매번 통계치가 바뀌지 않아야 함

가장 짧은 시간 내에 꼭 필요한 만큼만 데이터를 읽어 충분한 신뢰 수준을 갖춘 안정적인 통계정보를 옵티마이저에게 제공하려면 치밀한 전략이 있어야 한다. 자신이 관리하는 시스템 여건에 맞는 전략이 필요한 것이다.

어떤 테이블은 여러 파티션에 골고루 갱신이 이루어지는가 하면, 어떤 테이블은 특정 파티션에만 갱신이 이루어지기도 한다. 유지보수를 위한 서비스 다운타임이 매일 확보되는 시스템이 있는가 하면 24시간 가용성이 요구되는 시스템도 있다. OLTP냐 DW냐에 따라서도 다른 전략을 사용해야 한다. 또한 데이터 자체 특성에 따라서도 다른 전략이 필요한데, 만약 샘플 크기를 최소화하더라도 정확성, 안정성을 확보할 수 있다면 시간을 크게 줄일 수 있지만 그렇지 않다면 시간이 오래 걸리더라도 전수검사를 해야만 한다.

#### 주기적으로 통계 수집하면서 안정적이어야 최적

통계정보의 중요성은 무엇보다 좋은 실행 계획을 통해 쿼리 성능을 높이는 데 있다. 따라서 정확성이 무엇보다 중요하며, 특히 OLAP처럼 비정형(adhoc) 쿼리들이 많은 시스템에선 시스템 성능을 결정짓는 가장 중요한 변수로 작용한다.

하지만 절대적인 최적의 성능을 구현하기보다 안정적인 운영을 바라는 OLI P Production 시스템 관리자 입장에서는 통계정보의 안정성이 더 중요할 수 있다. 그런 연유로, 통계정보 수집을 꺼리는 DB 관리자들도 상당수 있다.

실제 통계정보를 수집하지 않고 오라클을 운영하는 고객사를 두 군데 경험한 적이 있는데, 한 곳은 원래 통계정보를 수집했으나 몇 번 장애를 경험하고는 어느 순간부터 수집을 멈춘 경우였다. 다른 한 곳은 초기부터 아예 통계정보 없이 운영을 시작한 경우였다. 오라클 버전은 둘 다 9i 였다.

이 두 회사의 공통점은 개발팀의 SQL 힌트 구사 능력이 웬만한 전문가 수준 이상이라는 점이다. 힌트 없이는 제대로 된 실행 계획을 기대하기 어려운 지경에 이르렀고, 이제라도 통계정보를 수집하자고 하면 어떤 사태가 벌어질지 몰라 손사래를 치는 형국이다.

두 번째 회사의 경우 최근에 방문해보니 조만간 RAC를 도입하면서 10g 버전으로 업그레이드 할 계획이라는 얘기를 들었다. 놀라운 것은, 10g에서도 계속해서 통계정보 없이 운영할 생각을 갖고 있더라는 사실이다. 필자가 우려를 표시했음에도 지금까지 통계정보 없이 운영하던 터라 불안해 서 어쩔 수 없다는 것이다.

안정성이 중요하더라도 CBO를 사용하는 한 통계정보를 수집하지 않을 수 없다는 사실을 기억하기 바란다. 통계정보를 주기적으로 수집하면서도 안정적으로 운영되는 시스템이야 말로 최적이라고 할 수 있으며, 이를 위해선 시스템 환경에 맞는 전략적인 통계 수집 정책이 반드시 필요하다.

#### 통계수집정책 수립은 필수

몇 가지 운영 전략을 소개하면, 통계를 수집할 필요가 없는 오브젝트에 대해서는 Lock 옵션으로 통계정보를 고정할 수 있다. 그리고 통계정보에 영향을 받아선 안 되는 중요한 일부 핵심 프로그램에 대해선 옵티마이저 힌트를 적용해 실행계획을 고정시키는 것이 최선이다.

운영 DB에서 수집한 통계정보를 개발 DB에도 반영한 상태에서 개발을 진행해야 하며, 프로그램을 운영 서버에 배포하기 전 충분한 테스트를 거쳐야 한다. 운영 서버와 테스트 서버간에는 오브젝트 통계 뿐만 아니라 시스템 통계까지 일치시켜야 하며, 당연히 옵티마이저 관련 파라미터도 일치시켜야 한다.

통계정보 변화 때문에 애플리케이션 성능에 심각한 문제가 발생했을 때를 대비해 가장 안정적이었던 최근 통계정보를 항상 백업해두기 바란다. 그래야 정상적이던 이전 상태로 빠르게 되돌릴 수 있다.

전략을 세우는 가장 세부단계에서는 아래 표에 예시한 것처럼 오브젝트별 통계수집 주기와 샘플링 비율 등을 표로 정리해두어야 한다.

![](/assets/images/sqlp/sqlp2-03-08-1-table1.png)

테이블 정의서에 기록하든 별도 산출물을 이용하든 데이터베이스 설계 시 주요 태스크로 진행해야 하고`7)`, 이를 기준으로 스크립트를 작성해 시스템 오픈 전에 적정성 여부를 반드시 테스트해야 한다. 뒤에서 설명할 자동 수집 기능을 이용하더라도 그 안에 이 같은 전략을 담고 있어야지, 모든 걸 자동 기능에 의존한다면 시스템 운명을 오라클에 내맡기는 것과 다름없다.

> 7.  이미 운영 중인 시스템이라면 DBA 팀 역할이라고 보는 것이 자연스럽지만 신 시스템을 설계하고 구축 중이라면 어느 팀 역할이라고 단정하기 어렵다. 기본 정책은 DBA 팀이 수립하겠지만 그에 따라 오브젝트별 통계수집 주기를 설계하는 일은 프로젝트 규모와 역할 정의에 따라 다를 수 있다. DBA, DA 누가 담당하는 데이터 발생 주기를 잘 아는 개발팀 또는 현업 담당자의 도움이 필요하며, 고성능 데이터베이스 구축을 위해서는 공동의 노력하에 반드시 거쳐야 할 매우 중요한 태스크라는 인식을 공유해야 한다.

이런 사전 준비와 테스트 과정 없이 시스템을 오픈하는 경우가 얼마나 많은가? 다시 강조하지만 시스템 여건과 오브젝트 특성에 맞는 통계수집 정책을 마련하지 않고는 안정적인 고성능 데이터베이스 구축은 요원한 일이다.

지금부터 시스템 환경에 따라 최적의 통계수집 정책을 수립하기 위해 어떤 옵션을 선택할 수 있는지 자세히 살펴보자.

### (2) DBMS_STATS

통계 정보 수집을 위해 오랫동안 사용되어 온 Analyze 명령어를 버리고 이제는 dbms_stats 패키지를 사용하는 것이 바람직하다. dbms_stats가 더 정교하게 통계를 계산해내기 때문이며, 특히 파티션 테이블/인덱스일 때는 반드시 dbms_stats를 사용해야 한다.

dbms_stats.gather_table_stats 프로시저의 인자를 표로 정리해 보면 다음과 같다. 참고로 버전마다 옵션 리스트와 기본 선택값이 조금씩 다르며, 여기서는 10g를 기준으로 설명하겠다.

![](/assets/images/sqlp/sqlp2-03-08-2-table1-1.png)
![](/assets/images/sqlp/sqlp2-03-08-2-table1-2.png)

### (3) 컬럼 히스토그램 수집

히스토그램을 가지면 더 나은 실행계획을 수립하는 데 도움이 되지만 이를 수집하고 관리하는 비용이 만만치 않다. 따라서 필요한 컬럼에만 히스토그램을 수집해야 하며, 조건절에 자주 사용되면서 편중된(skewed) 데이터 분포를 갖는 컬럼이 주 대상이다.

흔히 인덱스 컬럼에만 히스토그램이 필요하다고 생각하기 쉬운데, 그렇지 않다. 테이블을 액세스한 후에 최종 선택도를 계산할 때는 인덱스가 없는 조건 컬럼의 선택도도 인자로 사용되고, 그렇게 구해진 선택도에 따라 다른 집합과의 조인 순서 및 조인 방식이 결정되기 때문에 히스토그램이 필요하다. 인덱스 컬럼 조건에 대한 선택도를 가지고 인덱스 사용 여부를 결정하게 되므로 인덱스 컬럼에는 두말할 것도 없이 히스토그램이 중요하다.

아래와 같은 컬럼에는 히스토그램이 불필요하다.

- 컬럼 데이터 분포가 균일
- Unique하고 항상 등치 조건으로만 검색되는 컬럼
- 항상 바인드 변수로 검색되는 컬럼

dbms_stats.gather_table_stats에서 컬럼 히스토그램 수집과 관련된 인자는 method_opt이다. 8i와 9i에서의 기본 값은 'for all columns size 1' 이었는데 이는 모든 컬럼에 대해 히스토그램을 수집하지 말라는 의미다.

그런데 10g부터 기본값이 'for all columns size auto'로 바뀌었고 이는 오라클이 모든 컬럼에 대해 skew 여부를 조사해서 버킷 개수를 결정하라는 뜻이다. auto가 skew only와 다른 점은 해당 컬럼이 조건절에 사용되는 비중까지 고려해서 결정한다는 점이다. 이를 위해 오라클은 sys.colusage% 뷰를 참조한다.

10g에서 dbms_stats의 기본 동작 방식이 변경된 사실을 모른 채 시스템을 업그레이드 했다간 낭패를 보는 경우가 종종 발생하므로 주의하기 바란다.

없던 히스토그램이 생기면서 주요 SQL의 실행계획이 오히려 나쁜 쪽으로 바뀌는 예도 있거니와 통계 정보 수집 시간이 늘어나는 문제도 간과할 수 없다. 특히, 큰 테이블일수록 디스크 소트 부하 때문에 시간이 오래 걸린다. (그나마 auto는 조건절 사용 비중까지 고려해 히스토그램 생성 컬럼을 결정하므로 Skew only보다 조금 빠르다.)

통계 수집에 걸리는 시간이 짧은 테이블은 기본값으로 두어도 상관 없지만, 대용량 테이블일 때는 관리자가 직접 히스토그램 수집 컬럼을 아래와 같이 지정해주는 것이 바람직하다.

```
method opt →'for columns coll size 20 col2 size 254 col3 size 100'
```

10g부터는 기본값을 table-driven 방식으로 관리하므로 만약 dbms_stats 기본 동작 방식이 문제를 일으킨다면 dbms_stats.set_param 프로시저를 통해 기본값을 이전처럼 돌려놓을 수 있다.

### (4) 데이터 샘플링

샘플링 비율을 높일수록 통계 정보의 정확도는 높아지지만 통계 정보를 수집하는 데 더 많은 시간이 소요된다. 반대로 샘플링 비율을 낮추면 정확도는 다소 떨어지지만 더 효율적이고 빠르게 통계를 수집할 수 있다.

#### 샘플링 비율

dbms_stats 패키지에서 샘플링 비율을 조정하기 위해 estimate percent 인자를 사용한다. 이 값을 무작정 크게 한다고 정확도가 선형적으로 증가하는 것은 아니며, 일정 비율 이상이면 대개 충분한 신뢰 수준에도 달한다. 따라서 각 테이블별로 적정 샘플링 비율을 조사할 필요가 있는데, 모든 테이블을 조사 대상으로 삼기는 쉽지 않으므로 가장 큰 몇몇 테이블만 그렇게 하더라도 상당한 효과를 얻을 수 있다. 5%(-> 대개 이 정도면 충분한 신뢰 수준을 보임)에서 시작해 값은 늘려가며 두세 번만 통계를 수집해보면 적정 크기를 결정할 수 있다.

#### 블록 단위 샘플링

block_sample 인자를 통해 블록 단위 샘플링을 할지 로우 단위 샘플링을 할지 결정한다. 블록 단위 샘플링이 더 빠르고 효율적이긴 하지만 데이터 분포가 고르지 않을 때 정확도가 많이 떨어진다. 기본값은 로우 단위 샘플링이다.

#### 안정적인 통계 정보의 필요성

전수검사할 때는 그런 일이 없겠지만 샘플링 방식을 사용하면 매번 통계치가 다르게 구해질 수 있고 이는 실행계획에 영향을 미쳐 SQL 성능을 불안정하게 만든다.

특히 컬럼에 Null 값이 많거나 데이터 분포가 고르지 않을 때 그렇다. 선택도 구하는 공식의 세 가지 구성 요소가 Null 값을 제외한 로우 수, Distinct Value 개수, 총 레코드 개수를 상기하길 바란다. 특히, 총 레코드 개수에 비해 나머지 두 통계치는 컬럼 분포가 고르지 않을 때 샘플링 비율에 의해 크게 영향을 받는다.

#### 해시 기반 알고리즘으로 NDV 계산 - 11g

컬럼 히스토그램을 사용할 수 없을 때는 NDV(number of distinct values )를 가지고 선택도를 계산하므로 이 값의 정확도가 매우 중요하다. 그런데 방금 얘기했듯이 분포가 고르지 않은 상황에서 샘플링 방식을 사용하면 이 값이 매번 다르게 구해질 수 있어 안정적인 실행 계획을 기대하기 어렵다.

그래서 오라클 11g는 해시 기반의 새로운 알고리즘을 고안해냈고, 대용량 파티션 또는 테이블 전체를 스캔하더라도 기존에 샘플링 방식을 사용할 때보다 오히려 빠른 속도를 낼 수 있게 되었다. 소트를 수행하지 않기 때문이며, 전체를 대상으로 NDV를 구하므로 정확도는 당연히 100%에 가깝다. 빠르고, 정확하면서도 안정적인 통계 정보를 구현할 수 있게 된 것이다.

### (5) 파티션 테이블 통계 수집

파티션테이블일때오라클은테이블레벨통계('global 통계'라고함)와파티션레벨통계를따로
관리한다.

• 파티션레벨통계: StaticPartitionPruning이작동할때사용된다. 결합파티션일때는서 브파티션레벨로통계를관리할수도있다.
• 테 이 블 레 벨 통 계 : D y n a m i c P a r t i t i o n P r u n i n g 이 작 동 할 때 사 용 된 다. 쿼 리 에 바 인 드 변 수가사용됐거나, 파티션테이블이NIL조인에서Inner 쪽테이블이면액세스해야할대상 파티션목록을쿼리최적화시점에정할수없기때문이다. 또한파티션키에대한조건절이 없을때도테이블레벨통계가사용된다.

analyze명령을이용해통계정보를구하는것은deprecated된기능이라고설명했는데, 파티 션테이블일때특히그렇다. dbms_stats은global통계를위한쿼리를별도로수행하는반면,
analyze는파티션통계를가지고global 통계를유추하므로부정확하다.

d omsstats패키지를이용해파티션테이블의통계를수집할때는granularity옵션을신중하 게잘선택해줘야하며, 아래와같은값들이선택가능하다.

• global :테이블레벨통계수집
• partition:파티션레벨통계수집
• subpartition: 서브파티션레벨통계수집
• globalandpartition:테이블과파티션레벨통계수집 • all: 테이블, 파티션, 서브파티션레벨통계수집
• auto:파티션유형에따라오라클이결정

' global' 은테이블레벨통계를수집하고,partition' 은파티션레벨통계를수집한다.파티션 레벨통계를수집할때테이블레벨통계가미리수집돼있으면그대로두지만, 그렇지않을때는 파티션레벨통계로부터추정된값으로테이블레벨통계를설정한다.

참고로,dba/al /user_tables에서볼수있는항목중globalstats은테이블레벨통계수치들 이어떻게구해졌는지를알려준다. 즉, 테이블레벨통계를따로수집했다면YES, 파티션통계 를이용해추정했다면NO로표시된다.

테이블통계와파티션통계를같이수집하려면' g obal and par tition' 을선택하면된다. 내부적 으로global 통계를위한쿼리를한번더수행하므로각각수집할때와비교해속도차이는없다.

쿼리를한번더수행할필요없이파티션통계를이용해테이블전체통계를구하면될것같은 데오라클이그렇게하지않는이유는NDV때문이다. 예를들어, 어떤컬럼의NDV가파티션P1 과P2에서각10개와20개일때테이블레벨NDV는몇개인지추정할수있겠는가? 물론20
과 3 0 사 이 의 값 이 라 는 것 쯤 은 추 정 할 수 있 지 만 그 중 하 나 를 선 택 할 수 는 없 다.

• 20: P2에있는어떤컬럼값의집합(Domain)이PI의값집합을완전히포함할때 • 30: 어떤컬럼값의집합이P1, P2간에완전히배타적일때

그림3-6에예시한케이스1은테이블레벨NDV가20이고, 케이스2는26이다.

Range파티션테이블은대개새파티션을추가하면그곳에만데이터가입력되는데, 통계를수 집하려고대용량파티션테이블전체를두번스캔하는것은문제가있어보이지않는가? 그렇다 고데이터가 입력되는파티션만 통계정보를계속갱신한다면테이블통계는어느순간부터매우 부 정확한상태에놓이게된다. NDV는물론1owvalue/hi gh_value 와히스토그램이특히그렇다.

실제이문제로골머리를앓는DBA가많고, 파티션테이블에대한통계관리소홀로시스템정 애가발생하는예도잦다. 대용량파티션테이블에대한통계수집효율성을높일방안과전략이 필요해보인다.

10g 이하버전을사용하고있다면, 아래처럼최근파티션만통계를수집하고나서테이블전체 통계를한번더수행하는방식을사용하는것이효과적이다. 테이블마다프로시저를두번호출 하도록스크립트를작성하는것이성가시더라도어쩔수없다.

#### NDV를제외한Incremental Global 통계- 10.2.0.4

1 0 . 2 . 0 . 4 버 전 9 에 서 g r a n u l a r i t y 인 자 에 선 택 할 수 있 는 값 으 로 서, ' a p p r o x g l o b a l a n d p artition 이추가되었다. 이옵션이'globalandpartition과다른점은,테이블통계를위한쿼 리를따로수행하지않고파티션레벨통계로부터집계한다는데에있다. 테이블레벨컬럼히스토 그램도파티션레벨로부터집계한다. 단, 컬럼NDV와인덱스의Distinct Key개수는제외된다.

#### NDV를포함한완벽한Incremental Global 통계- 11g

앞에서, 전체데이터를읽지만소트없이해시방식으로빠르게NDV를구하는11g 신기능을소 개했는데, 1g에선파티션레벨NDV를이용해Global NDV를정확히구할수있는방법까지제 공하기시작했다.

파티션레벨NDV로부터테이블레벨NIDV를구하는것이불가능하다고설명했는데, 어떻게 1 1 g 에 서 가 능 해 진 것 일 까 ? 오 라 클 은N D V 를 포 함 한 I n c r e m e n t a l G l o b a l 통 계 수 집 ' 기 능 을 제 공하려고파티션레벨컬럼별로t ynopss라고하는별도의메타데이터를관리(Sysus테이블스페 이스에저장)하기로하였다.

synopsis는Distinct Value에대한샘플( 그림3-6에표현된각원소)이라고생각하면된다. 모든파 티션마다각컬럼이갖는값의집합(Domain)을보관했다가이를머지(merge)함으로써Global NDV
를 구한다. (기존에는집합개수만보관했기때문에불가능했던것이다. )

사실I ncremental Global 통계수집기능은당연히제공됐어야할기능이다. 그렇지못한상태 에 서 오 라 클 1 0 g 부 터 자 동 통 계 수집 기 능( 뒤에 서 설명함) 이 기 본 으로 설 정 된 것 을 보 고 적 잖 은 우 려 가됐었다. 현재기업들이보유한엄청난데이터량을감안하면매번대용량파티션테이블을두 번씩읽는기존방식의문제점을쉽게예상할수있다.

실제이옵션을그대로받아들인시스템들이긴통계수집시간때문에곤혹을치렀고, 곳곳에 서 아 우 성 하 니 까 부 랴 부 랴 1 0 . 2 . 0 . 4 에 서 패 치 를 통 해 ' N DV 를 제 외 한 I n c r e m e n t a l 방 식' 을 제 공하게된것이다. 늦긴했지만11g에서' NDV까지포함한Ineremental Global 통계' 를수집할 수있도록개선한것은무척다행스럽고, 이제는자동통계수집기능을이용해볼만하다는생각
이든다.

### (6) 인덱스통계수집

테이블통계를수집하면서cascade 옵션을true로설정하면테이블에속한모든인덱스통계도 같이수집된다. 통계를같이수집한다고해서더빠른것은아니며, 인덱스마다gatheri ndex\_
st at s 프로시저를따로수행하는것과일량은같다.

문제는, 대용량테이블이어서샘플링비율을지정하면인덱스통계까지도같은비율이적용된 다는데에있다. 인덱스는통계수집에걸리는시간은매우짧아굳이샘플링방식을사용할필요 가없는데도말이다. (테이블통계수집에는소트연산이발생하지만인덱스는이미정렬된상태여서소트연산이불필 요하기때문에빠르다.)

그럴때는아래와같이테이블통계만샘플링방식을사용하고, 인덱스는전수검사하도록각기 통계를수집해주는것이좋다.

```
begin
-- 테이블.통계는estimatemode
dons stats.gather table stats ( user, 'big table', cascade→ false estimate percent=>10) ;
- 인덱스통계는c omput emode
dons stats. gather_ index stats (user, 'big table pk', estimate percent→> 10 ): doms stats.gather index stats ( user, 'big table x1', estimate percent→>100 ); end;
/
```

### (7) 캐싱된커서Invalidation

noinvalidate 옵션을어떻게지정하느냐에따라통계를수집한테이블과관련된SQL커서의 무효화시점이달라진다.

•f alse: 통계정보변경시관련된SQL커서들이즉시무효화된다. 따라서곧이어첫번째수 행하는세션에의해, 새로갱신된통계정보를이용한실행계획이로드(하드파싱)된다.
• true:통계정보변경시관련된SQL커서들을무효화하지않는다. SQL커서가자동으로 Shar ed Pool에서밀려났다가다시로드될때비로소새로갱신된통계정보를사용한다.
• dbms_stats.auto_invalidate: 통계정보변경시관련된SQL커서들을한꺼번에무효화하 지않고정해진시간(nvalidaiontimewindow)동안조금씩무효화한다. 무효화된수많은커서 가동시에수행되면서하드파싱에 의한라이브러리캐시 경합이발생하는현상을방지하려 고10g에서도입된기능이다.

중요한것은, 9i에서false이던기본값이10g에서dbms.\_stats,auto_invalidate로바뀌었다는 사실이다. 따라서기존통계수집스크립트를그대로사용하면관련SQL. 커서들이곧바로무효 화되지않는현상이발생한다.

이 기 능 을제 어 하 는 파 라 미 터 는 _ o p t i m i z e r _ i n v a l i d a t i o n p e r i o d 이 고 , 기 본 값 은1 8 , 0 0 0 초 다 . 즉, 늦어도5시간이내에는관련SQL커서가무효화된다.

### (8) 자동통계수집

오라클10g부터기본적으로매일밤10시부터다음날아침6시까지모든살 자오브젝트에대 한통계를자동수집하도록100이등록돼있다. 이기능은gatherstatsj op에의해자동수행되 며, 통계정보가없거나통계정보수집후DML이많이발생(\_ab.statstcs뷰에서Stal.slais컬럼참조) 한모든오브젝트를대상으로한다.

#### GATHER STATS_JOB

gather_stats_job은데이터베이스생성시자동으로등록되며, Maintenance윈도우그룹 (maintenance_window_group)에등록된윈도우가열릴때마다스케쥴러에의해수행된다.

#### 통계정보 갱신 대상 식별

오라클은통계정보수집이필요한오브젝트인지를판별하기위해테이블모니터링기능을제공
한다. 9i에서는nomonitoring옵션이기본이었고필요한테이블에만관리자가아래와같이 monitoring옵션을지정했지만10g에서는이옵션이아예deprecated 돼모든사용자테이블이
모니터링되고있다.

alter table emp monitoring;

s t a t i s t i c s l e v e l 이t y p i c a l 또 는a l l 일 때 오 라 클 은 , m o n i t o r i n g 옵 션 이 지 정 된 테 이 블 에 발 생 하는DMIL발생량을모니터링한다. 수집된테이블별DML발생량은\*\_ tab_modifications 뷰를 통해조회해볼수있으며, inserts, updates, deletes컬럼에표시된수치는마지막통계정보가 수집된이후의DMIL발생량이다.

오라클은모니터링대상테이블에10%이상변경이발생했을때해당테이블을s tale/상태 ( Jabstanistes뷰에서stale-stais=VES) 로바꾼다.그러고나서gather_database_stat s또는 g ather_schema_stats프로시저를호출하면서option인자에gatherstale'또는gather auto. 를지정하면stale상태인테이블들에대해통계정보를새로수집한다. 참고로, 11g에서는
s t a l e 상 태 로 바 뀌 는 임 계 치 를 오 브 젝 트 별 로 조 정 할 수 있 다.

실제테스트해보면테이블에10% 이상변경을가하더라도*\_ tab_modifications과 *_tab.statistics뷰stalestats컬럼에변화가생기지않는것을발견한다. 이는모니터링결과 를 S h a r e d P o o l 에 모 았 다 가 S M O N 이 주 기 적 으 로 ( 대 략 3 시 간) 데 이 터 딕 셔 너 리 에 반 영 하 기 때 문 이 다. 현재까지의변경사항이딕셔너리에바로반영되도록하려면dbms_stats,fush_database_ monitoring info 프로시저를호출하면된다.

#### 자동 통계 수집 기능 활용 가이드

평 소관심을두지않다가일년에한두번쯤생각날때만통계정보를수집하는DBA팀을종종 보는데, 그런경우라면오라클이제공하는자동수집기능에라도의존하는것이나을수있다.
1 0g에서자동통계수집기능이활성화된사실을모르고매일새벽수동으로통계정보를수집하는경우도본적이있는데, 결과적으로통계정보를두번씩수행하는셈이다.)

하지만중대형급이상데이터베이스를관리한다면10g에서제공하는자동통계수집기능은사 용하지않는편이좋겠다. 특히,Maintenance윈도우이내에통계수집이완료되지않는경우가 생기면시스템을불안정한상태에빠뜨릴수있으므로주의해야한다. 될수있으면앞에서설명
한것처럼오브젝트별전략을세우고가장짧은시간내에정확하고안정적인통계정보를수집할 수있도록별도의스크립트를준비하는것이좋다.

11g에서는, 앞서소개한여러기능과바로이어서설명할Statistics Preference기능때문에 자동통계수집기능이꽤쓸만해졌다. 그렇더라도오브젝트별수집전략은여전히필요하며, 과 거에스크립트를직접작성하던것이이제파라미터driven 방식으로바뀐것에불과하다. 개별 오브젝트별선택사양을입력해두면자동수집기능이작동할때오라클이 그내용에따라통계정 보를수집해준다.

### (9) Statistics Preference

지금까지설명한몇가지이유때문에오라클10g에서는자동통계 수집기능을그대로사용하 기에무리가따른다. gat her_stats job을제거하고시스템환경과애플리케이션특성에맞게설 계된별도의프로시저를작성해서Jj0b에등록해주는것이바람직하다.

오브젝트별로일일이스크립트를작성하는게귀찮아자동통계수집기능을그대로사용하고 싶다면,기본설정을적용하고싶지않은오브젝트에만1ock 을설정(dar s.statslocklablestats프로시
저참조한상태에서전체통계를수집하는방법을생각해볼 수있다.전체통 계수집이끝나면 lock을설정했던오브젝트에1ock을풀고통계를수집하는, 별도의job을수행하면된다.

관리자들의 그런불편을모를리없는오라클이11g에서매우유용한기능을선보였다. St atistics Preference 라고불리는기능으로서gather_statsj ob을그대로활성화한상태에서 테이블또는스키마별로통계수집방식을따로설정할수있게한것이다. 그러면자동통계수집 기능이작동할때해당테이블또는스키마에대해서는기본설정값을무시하고사용자지시사항
에따라통계정보를수집한다.

이제시스템여건과테이블 특성에맞는통계수집정책을자동통계 수집기능에반영할 수있
게되었고, 이기능과Incremental Clobal 통계기능을이용함으로써11g에서자동통계수집기 능의활용가능성이훨씬높아졌다.
